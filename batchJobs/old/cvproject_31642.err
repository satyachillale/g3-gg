Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:01,  2.52it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  2.53it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:01<00:00,  2.61it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  2.09it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  2.24it/s]
Some weights of LlavaForConditionalGeneration were not initialized from the model checkpoint at lmms-lab/llama3-llava-next-8b and are newly initialized: ['model.language_model.lm_head.weight', 'model.language_model.model.embed_tokens.weight', 'model.language_model.model.layers.0.input_layernorm.weight', 'model.language_model.model.layers.0.mlp.down_proj.weight', 'model.language_model.model.layers.0.mlp.gate_proj.weight', 'model.language_model.model.layers.0.mlp.up_proj.weight', 'model.language_model.model.layers.0.post_attention_layernorm.weight', 'model.language_model.model.layers.0.self_attn.k_proj.weight', 'model.language_model.model.layers.0.self_attn.o_proj.weight', 'model.language_model.model.layers.0.self_attn.q_proj.weight', 'model.language_model.model.layers.0.self_attn.v_proj.weight', 'model.language_model.model.layers.1.input_layernorm.weight', 'model.language_model.model.layers.1.mlp.down_proj.weight', 'model.language_model.model.layers.1.mlp.gate_proj.weight', 'model.language_model.model.layers.1.mlp.up_proj.weight', 'model.language_model.model.layers.1.post_attention_layernorm.weight', 'model.language_model.model.layers.1.self_attn.k_proj.weight', 'model.language_model.model.layers.1.self_attn.o_proj.weight', 'model.language_model.model.layers.1.self_attn.q_proj.weight', 'model.language_model.model.layers.1.self_attn.v_proj.weight', 'model.language_model.model.layers.10.input_layernorm.weight', 'model.language_model.model.layers.10.mlp.down_proj.weight', 'model.language_model.model.layers.10.mlp.gate_proj.weight', 'model.language_model.model.layers.10.mlp.up_proj.weight', 'model.language_model.model.layers.10.post_attention_layernorm.weight', 'model.language_model.model.layers.10.self_attn.k_proj.weight', 'model.language_model.model.layers.10.self_attn.o_proj.weight', 'model.language_model.model.layers.10.self_attn.q_proj.weight', 'model.language_model.model.layers.10.self_attn.v_proj.weight', 'model.language_model.model.layers.11.input_layernorm.weight', 'model.language_model.model.layers.11.mlp.down_proj.weight', 'model.language_model.model.layers.11.mlp.gate_proj.weight', 'model.language_model.model.layers.11.mlp.up_proj.weight', 'model.language_model.model.layers.11.post_attention_layernorm.weight', 'model.language_model.model.layers.11.self_attn.k_proj.weight', 'model.language_model.model.layers.11.self_attn.o_proj.weight', 'model.language_model.model.layers.11.self_attn.q_proj.weight', 'model.language_model.model.layers.11.self_attn.v_proj.weight', 'model.language_model.model.layers.12.input_layernorm.weight', 'model.language_model.model.layers.12.mlp.down_proj.weight', 'model.language_model.model.layers.12.mlp.gate_proj.weight', 'model.language_model.model.layers.12.mlp.up_proj.weight', 'model.language_model.model.layers.12.post_attention_layernorm.weight', 'model.language_model.model.layers.12.self_attn.k_proj.weight', 'model.language_model.model.layers.12.self_attn.o_proj.weight', 'model.language_model.model.layers.12.self_attn.q_proj.weight', 'model.language_model.model.layers.12.self_attn.v_proj.weight', 'model.language_model.model.layers.13.input_layernorm.weight', 'model.language_model.model.layers.13.mlp.down_proj.weight', 'model.language_model.model.layers.13.mlp.gate_proj.weight', 'model.language_model.model.layers.13.mlp.up_proj.weight', 'model.language_model.model.layers.13.post_attention_layernorm.weight', 'model.language_model.model.layers.13.self_attn.k_proj.weight', 'model.language_model.model.layers.13.self_attn.o_proj.weight', 'model.language_model.model.layers.13.self_attn.q_proj.weight', 'model.language_model.model.layers.13.self_attn.v_proj.weight', 'model.language_model.model.layers.14.input_layernorm.weight', 'model.language_model.model.layers.14.mlp.down_proj.weight', 'model.language_model.model.layers.14.mlp.gate_proj.weight', 'model.language_model.model.layers.14.mlp.up_proj.weight', 'model.language_model.model.layers.14.post_attention_layernorm.weight', 'model.language_model.model.layers.14.self_attn.k_proj.weight', 'model.language_model.model.layers.14.self_attn.o_proj.weight', 'model.language_model.model.layers.14.self_attn.q_proj.weight', 'model.language_model.model.layers.14.self_attn.v_proj.weight', 'model.language_model.model.layers.15.input_layernorm.weight', 'model.language_model.model.layers.15.mlp.down_proj.weight', 'model.language_model.model.layers.15.mlp.gate_proj.weight', 'model.language_model.model.layers.15.mlp.up_proj.weight', 'model.language_model.model.layers.15.post_attention_layernorm.weight', 'model.language_model.model.layers.15.self_attn.k_proj.weight', 'model.language_model.model.layers.15.self_attn.o_proj.weight', 'model.language_model.model.layers.15.self_attn.q_proj.weight', 'model.language_model.model.layers.15.self_attn.v_proj.weight', 'model.language_model.model.layers.16.input_layernorm.weight', 'model.language_model.model.layers.16.mlp.down_proj.weight', 'model.language_model.model.layers.16.mlp.gate_proj.weight', 'model.language_model.model.layers.16.mlp.up_proj.weight', 'model.language_model.model.layers.16.post_attention_layernorm.weight', 'model.language_model.model.layers.16.self_attn.k_proj.weight', 'model.language_model.model.layers.16.self_attn.o_proj.weight', 'model.language_model.model.layers.16.self_attn.q_proj.weight', 'model.language_model.model.layers.16.self_attn.v_proj.weight', 'model.language_model.model.layers.17.input_layernorm.weight', 'model.language_model.model.layers.17.mlp.down_proj.weight', 'model.language_model.model.layers.17.mlp.gate_proj.weight', 'model.language_model.model.layers.17.mlp.up_proj.weight', 'model.language_model.model.layers.17.post_attention_layernorm.weight', 'model.language_model.model.layers.17.self_attn.k_proj.weight', 'model.language_model.model.layers.17.self_attn.o_proj.weight', 'model.language_model.model.layers.17.self_attn.q_proj.weight', 'model.language_model.model.layers.17.self_attn.v_proj.weight', 'model.language_model.model.layers.18.input_layernorm.weight', 'model.language_model.model.layers.18.mlp.down_proj.weight', 'model.language_model.model.layers.18.mlp.gate_proj.weight', 'model.language_model.model.layers.18.mlp.up_proj.weight', 'model.language_model.model.layers.18.post_attention_layernorm.weight', 'model.language_model.model.layers.18.self_attn.k_proj.weight', 'model.language_model.model.layers.18.self_attn.o_proj.weight', 'model.language_model.model.layers.18.self_attn.q_proj.weight', 'model.language_model.model.layers.18.self_attn.v_proj.weight', 'model.language_model.model.layers.19.input_layernorm.weight', 'model.language_model.model.layers.19.mlp.down_proj.weight', 'model.language_model.model.layers.19.mlp.gate_proj.weight', 'model.language_model.model.layers.19.mlp.up_proj.weight', 'model.language_model.model.layers.19.post_attention_layernorm.weight', 'model.language_model.model.layers.19.self_attn.k_proj.weight', 'model.language_model.model.layers.19.self_attn.o_proj.weight', 'model.language_model.model.layers.19.self_attn.q_proj.weight', 'model.language_model.model.layers.19.self_attn.v_proj.weight', 'model.language_model.model.layers.2.input_layernorm.weight', 'model.language_model.model.layers.2.mlp.down_proj.weight', 'model.language_model.model.layers.2.mlp.gate_proj.weight', 'model.language_model.model.layers.2.mlp.up_proj.weight', 'model.language_model.model.layers.2.post_attention_layernorm.weight', 'model.language_model.model.layers.2.self_attn.k_proj.weight', 'model.language_model.model.layers.2.self_attn.o_proj.weight', 'model.language_model.model.layers.2.self_attn.q_proj.weight', 'model.language_model.model.layers.2.self_attn.v_proj.weight', 'model.language_model.model.layers.20.input_layernorm.weight', 'model.language_model.model.layers.20.mlp.down_proj.weight', 'model.language_model.model.layers.20.mlp.gate_proj.weight', 'model.language_model.model.layers.20.mlp.up_proj.weight', 'model.language_model.model.layers.20.post_attention_layernorm.weight', 'model.language_model.model.layers.20.self_attn.k_proj.weight', 'model.language_model.model.layers.20.self_attn.o_proj.weight', 'model.language_model.model.layers.20.self_attn.q_proj.weight', 'model.language_model.model.layers.20.self_attn.v_proj.weight', 'model.language_model.model.layers.21.input_layernorm.weight', 'model.language_model.model.layers.21.mlp.down_proj.weight', 'model.language_model.model.layers.21.mlp.gate_proj.weight', 'model.language_model.model.layers.21.mlp.up_proj.weight', 'model.language_model.model.layers.21.post_attention_layernorm.weight', 'model.language_model.model.layers.21.self_attn.k_proj.weight', 'model.language_model.model.layers.21.self_attn.o_proj.weight', 'model.language_model.model.layers.21.self_attn.q_proj.weight', 'model.language_model.model.layers.21.self_attn.v_proj.weight', 'model.language_model.model.layers.22.input_layernorm.weight', 'model.language_model.model.layers.22.mlp.down_proj.weight', 'model.language_model.model.layers.22.mlp.gate_proj.weight', 'model.language_model.model.layers.22.mlp.up_proj.weight', 'model.language_model.model.layers.22.post_attention_layernorm.weight', 'model.language_model.model.layers.22.self_attn.k_proj.weight', 'model.language_model.model.layers.22.self_attn.o_proj.weight', 'model.language_model.model.layers.22.self_attn.q_proj.weight', 'model.language_model.model.layers.22.self_attn.v_proj.weight', 'model.language_model.model.layers.23.input_layernorm.weight', 'model.language_model.model.layers.23.mlp.down_proj.weight', 'model.language_model.model.layers.23.mlp.gate_proj.weight', 'model.language_model.model.layers.23.mlp.up_proj.weight', 'model.language_model.model.layers.23.post_attention_layernorm.weight', 'model.language_model.model.layers.23.self_attn.k_proj.weight', 'model.language_model.model.layers.23.self_attn.o_proj.weight', 'model.language_model.model.layers.23.self_attn.q_proj.weight', 'model.language_model.model.layers.23.self_attn.v_proj.weight', 'model.language_model.model.layers.24.input_layernorm.weight', 'model.language_model.model.layers.24.mlp.down_proj.weight', 'model.language_model.model.layers.24.mlp.gate_proj.weight', 'model.language_model.model.layers.24.mlp.up_proj.weight', 'model.language_model.model.layers.24.post_attention_layernorm.weight', 'model.language_model.model.layers.24.self_attn.k_proj.weight', 'model.language_model.model.layers.24.self_attn.o_proj.weight', 'model.language_model.model.layers.24.self_attn.q_proj.weight', 'model.language_model.model.layers.24.self_attn.v_proj.weight', 'model.language_model.model.layers.25.input_layernorm.weight', 'model.language_model.model.layers.25.mlp.down_proj.weight', 'model.language_model.model.layers.25.mlp.gate_proj.weight', 'model.language_model.model.layers.25.mlp.up_proj.weight', 'model.language_model.model.layers.25.post_attention_layernorm.weight', 'model.language_model.model.layers.25.self_attn.k_proj.weight', 'model.language_model.model.layers.25.self_attn.o_proj.weight', 'model.language_model.model.layers.25.self_attn.q_proj.weight', 'model.language_model.model.layers.25.self_attn.v_proj.weight', 'model.language_model.model.layers.26.input_layernorm.weight', 'model.language_model.model.layers.26.mlp.down_proj.weight', 'model.language_model.model.layers.26.mlp.gate_proj.weight', 'model.language_model.model.layers.26.mlp.up_proj.weight', 'model.language_model.model.layers.26.post_attention_layernorm.weight', 'model.language_model.model.layers.26.self_attn.k_proj.weight', 'model.language_model.model.layers.26.self_attn.o_proj.weight', 'model.language_model.model.layers.26.self_attn.q_proj.weight', 'model.language_model.model.layers.26.self_attn.v_proj.weight', 'model.language_model.model.layers.27.input_layernorm.weight', 'model.language_model.model.layers.27.mlp.down_proj.weight', 'model.language_model.model.layers.27.mlp.gate_proj.weight', 'model.language_model.model.layers.27.mlp.up_proj.weight', 'model.language_model.model.layers.27.post_attention_layernorm.weight', 'model.language_model.model.layers.27.self_attn.k_proj.weight', 'model.language_model.model.layers.27.self_attn.o_proj.weight', 'model.language_model.model.layers.27.self_attn.q_proj.weight', 'model.language_model.model.layers.27.self_attn.v_proj.weight', 'model.language_model.model.layers.28.input_layernorm.weight', 'model.language_model.model.layers.28.mlp.down_proj.weight', 'model.language_model.model.layers.28.mlp.gate_proj.weight', 'model.language_model.model.layers.28.mlp.up_proj.weight', 'model.language_model.model.layers.28.post_attention_layernorm.weight', 'model.language_model.model.layers.28.self_attn.k_proj.weight', 'model.language_model.model.layers.28.self_attn.o_proj.weight', 'model.language_model.model.layers.28.self_attn.q_proj.weight', 'model.language_model.model.layers.28.self_attn.v_proj.weight', 'model.language_model.model.layers.29.input_layernorm.weight', 'model.language_model.model.layers.29.mlp.down_proj.weight', 'model.language_model.model.layers.29.mlp.gate_proj.weight', 'model.language_model.model.layers.29.mlp.up_proj.weight', 'model.language_model.model.layers.29.post_attention_layernorm.weight', 'model.language_model.model.layers.29.self_attn.k_proj.weight', 'model.language_model.model.layers.29.self_attn.o_proj.weight', 'model.language_model.model.layers.29.self_attn.q_proj.weight', 'model.language_model.model.layers.29.self_attn.v_proj.weight', 'model.language_model.model.layers.3.input_layernorm.weight', 'model.language_model.model.layers.3.mlp.down_proj.weight', 'model.language_model.model.layers.3.mlp.gate_proj.weight', 'model.language_model.model.layers.3.mlp.up_proj.weight', 'model.language_model.model.layers.3.post_attention_layernorm.weight', 'model.language_model.model.layers.3.self_attn.k_proj.weight', 'model.language_model.model.layers.3.self_attn.o_proj.weight', 'model.language_model.model.layers.3.self_attn.q_proj.weight', 'model.language_model.model.layers.3.self_attn.v_proj.weight', 'model.language_model.model.layers.30.input_layernorm.weight', 'model.language_model.model.layers.30.mlp.down_proj.weight', 'model.language_model.model.layers.30.mlp.gate_proj.weight', 'model.language_model.model.layers.30.mlp.up_proj.weight', 'model.language_model.model.layers.30.post_attention_layernorm.weight', 'model.language_model.model.layers.30.self_attn.k_proj.weight', 'model.language_model.model.layers.30.self_attn.o_proj.weight', 'model.language_model.model.layers.30.self_attn.q_proj.weight', 'model.language_model.model.layers.30.self_attn.v_proj.weight', 'model.language_model.model.layers.31.input_layernorm.weight', 'model.language_model.model.layers.31.mlp.down_proj.weight', 'model.language_model.model.layers.31.mlp.gate_proj.weight', 'model.language_model.model.layers.31.mlp.up_proj.weight', 'model.language_model.model.layers.31.post_attention_layernorm.weight', 'model.language_model.model.layers.31.self_attn.k_proj.weight', 'model.language_model.model.layers.31.self_attn.o_proj.weight', 'model.language_model.model.layers.31.self_attn.q_proj.weight', 'model.language_model.model.layers.31.self_attn.v_proj.weight', 'model.language_model.model.layers.4.input_layernorm.weight', 'model.language_model.model.layers.4.mlp.down_proj.weight', 'model.language_model.model.layers.4.mlp.gate_proj.weight', 'model.language_model.model.layers.4.mlp.up_proj.weight', 'model.language_model.model.layers.4.post_attention_layernorm.weight', 'model.language_model.model.layers.4.self_attn.k_proj.weight', 'model.language_model.model.layers.4.self_attn.o_proj.weight', 'model.language_model.model.layers.4.self_attn.q_proj.weight', 'model.language_model.model.layers.4.self_attn.v_proj.weight', 'model.language_model.model.layers.5.input_layernorm.weight', 'model.language_model.model.layers.5.mlp.down_proj.weight', 'model.language_model.model.layers.5.mlp.gate_proj.weight', 'model.language_model.model.layers.5.mlp.up_proj.weight', 'model.language_model.model.layers.5.post_attention_layernorm.weight', 'model.language_model.model.layers.5.self_attn.k_proj.weight', 'model.language_model.model.layers.5.self_attn.o_proj.weight', 'model.language_model.model.layers.5.self_attn.q_proj.weight', 'model.language_model.model.layers.5.self_attn.v_proj.weight', 'model.language_model.model.layers.6.input_layernorm.weight', 'model.language_model.model.layers.6.mlp.down_proj.weight', 'model.language_model.model.layers.6.mlp.gate_proj.weight', 'model.language_model.model.layers.6.mlp.up_proj.weight', 'model.language_model.model.layers.6.post_attention_layernorm.weight', 'model.language_model.model.layers.6.self_attn.k_proj.weight', 'model.language_model.model.layers.6.self_attn.o_proj.weight', 'model.language_model.model.layers.6.self_attn.q_proj.weight', 'model.language_model.model.layers.6.self_attn.v_proj.weight', 'model.language_model.model.layers.7.input_layernorm.weight', 'model.language_model.model.layers.7.mlp.down_proj.weight', 'model.language_model.model.layers.7.mlp.gate_proj.weight', 'model.language_model.model.layers.7.mlp.up_proj.weight', 'model.language_model.model.layers.7.post_attention_layernorm.weight', 'model.language_model.model.layers.7.self_attn.k_proj.weight', 'model.language_model.model.layers.7.self_attn.o_proj.weight', 'model.language_model.model.layers.7.self_attn.q_proj.weight', 'model.language_model.model.layers.7.self_attn.v_proj.weight', 'model.language_model.model.layers.8.input_layernorm.weight', 'model.language_model.model.layers.8.mlp.down_proj.weight', 'model.language_model.model.layers.8.mlp.gate_proj.weight', 'model.language_model.model.layers.8.mlp.up_proj.weight', 'model.language_model.model.layers.8.post_attention_layernorm.weight', 'model.language_model.model.layers.8.self_attn.k_proj.weight', 'model.language_model.model.layers.8.self_attn.o_proj.weight', 'model.language_model.model.layers.8.self_attn.q_proj.weight', 'model.language_model.model.layers.8.self_attn.v_proj.weight', 'model.language_model.model.layers.9.input_layernorm.weight', 'model.language_model.model.layers.9.mlp.down_proj.weight', 'model.language_model.model.layers.9.mlp.gate_proj.weight', 'model.language_model.model.layers.9.mlp.up_proj.weight', 'model.language_model.model.layers.9.post_attention_layernorm.weight', 'model.language_model.model.layers.9.self_attn.k_proj.weight', 'model.language_model.model.layers.9.self_attn.o_proj.weight', 'model.language_model.model.layers.9.self_attn.q_proj.weight', 'model.language_model.model.layers.9.self_attn.v_proj.weight', 'model.language_model.model.norm.weight', 'model.multi_modal_projector.linear_1.bias', 'model.multi_modal_projector.linear_1.weight', 'model.multi_modal_projector.linear_2.bias', 'model.multi_modal_projector.linear_2.weight', 'model.vision_tower.vision_model.embeddings.class_embedding', 'model.vision_tower.vision_model.embeddings.patch_embedding.weight', 'model.vision_tower.vision_model.embeddings.position_embedding.weight', 'model.vision_tower.vision_model.encoder.layers.0.layer_norm1.bias', 'model.vision_tower.vision_model.encoder.layers.0.layer_norm1.weight', 'model.vision_tower.vision_model.encoder.layers.0.layer_norm2.bias', 'model.vision_tower.vision_model.encoder.layers.0.layer_norm2.weight', 'model.vision_tower.vision_model.encoder.layers.0.mlp.fc1.bias', 'model.vision_tower.vision_model.encoder.layers.0.mlp.fc1.weight', 'model.vision_tower.vision_model.encoder.layers.0.mlp.fc2.bias', 'model.vision_tower.vision_model.encoder.layers.0.mlp.fc2.weight', 'model.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.bias', 'model.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.weight', 'model.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.bias', 'model.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.weight', 'model.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.bias', 'model.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.weight', 'model.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.bias', 'model.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.weight', 'model.vision_tower.vision_model.encoder.layers.1.layer_norm1.bias', 'model.vision_tower.vision_model.encoder.layers.1.layer_norm1.weight', 'model.vision_tower.vision_model.encoder.layers.1.layer_norm2.bias', 'model.vision_tower.vision_model.encoder.layers.1.layer_norm2.weight', 'model.vision_tower.vision_model.encoder.layers.1.mlp.fc1.bias', 'model.vision_tower.vision_model.encoder.layers.1.mlp.fc1.weight', 'model.vision_tower.vision_model.encoder.layers.1.mlp.fc2.bias', 'model.vision_tower.vision_model.encoder.layers.1.mlp.fc2.weight', 'model.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.bias', 'model.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.weight', 'model.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.bias', 'model.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.weight', 'model.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.bias', 'model.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.weight', 'model.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.bias', 'model.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.weight', 'model.vision_tower.vision_model.encoder.layers.10.layer_norm1.bias', 'model.vision_tower.vision_model.encoder.layers.10.layer_norm1.weight', 'model.vision_tower.vision_model.encoder.layers.10.layer_norm2.bias', 'model.vision_tower.vision_model.encoder.layers.10.layer_norm2.weight', 'model.vision_tower.vision_model.encoder.layers.10.mlp.fc1.bias', 'model.vision_tower.vision_model.encoder.layers.10.mlp.fc1.weight', 'model.vision_tower.vision_model.encoder.layers.10.mlp.fc2.bias', 'model.vision_tower.vision_model.encoder.layers.10.mlp.fc2.weight', 'model.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.bias', 'model.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.weight', 'model.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.bias', 'model.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.weight', 'model.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.bias', 'model.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.weight', 'model.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.bias', 'model.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.weight', 'model.vision_tower.vision_model.encoder.layers.11.layer_norm1.bias', 'model.vision_tower.vision_model.encoder.layers.11.layer_norm1.weight', 'model.vision_tower.vision_model.encoder.layers.11.layer_norm2.bias', 'model.vision_tower.vision_model.encoder.layers.11.layer_norm2.weight', 'model.vision_tower.vision_model.encoder.layers.11.mlp.fc1.bias', 'model.vision_tower.vision_model.encoder.layers.11.mlp.fc1.weight', 'model.vision_tower.vision_model.encoder.layers.11.mlp.fc2.bias', 'model.vision_tower.vision_model.encoder.layers.11.mlp.fc2.weight', 'model.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.bias', 'model.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.weight', 'model.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.bias', 'model.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.weight', 'model.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.bias', 'model.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.weight', 'model.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.bias', 'model.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.weight', 'model.vision_tower.vision_model.encoder.layers.12.layer_norm1.bias', 'model.vision_tower.vision_model.encoder.layers.12.layer_norm1.weight', 'model.vision_tower.vision_model.encoder.layers.12.layer_norm2.bias', 'model.vision_tower.vision_model.encoder.layers.12.layer_norm2.weight', 'model.vision_tower.vision_model.encoder.layers.12.mlp.fc1.bias', 'model.vision_tower.vision_model.encoder.layers.12.mlp.fc1.weight', 'model.vision_tower.vision_model.encoder.layers.12.mlp.fc2.bias', 'model.vision_tower.vision_model.encoder.layers.12.mlp.fc2.weight', 'model.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.bias', 'model.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.weight', 'model.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.bias', 'model.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.weight', 'model.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.bias', 'model.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.weight', 'model.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.bias', 'model.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.weight', 'model.vision_tower.vision_model.encoder.layers.13.layer_norm1.bias', 'model.vision_tower.vision_model.encoder.layers.13.layer_norm1.weight', 'model.vision_tower.vision_model.encoder.layers.13.layer_norm2.bias', 'model.vision_tower.vision_model.encoder.layers.13.layer_norm2.weight', 'model.vision_tower.vision_model.encoder.layers.13.mlp.fc1.bias', 'model.vision_tower.vision_model.encoder.layers.13.mlp.fc1.weight', 'model.vision_tower.vision_model.encoder.layers.13.mlp.fc2.bias', 'model.vision_tower.vision_model.encoder.layers.13.mlp.fc2.weight', 'model.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.bias', 'model.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.weight', 'model.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.bias', 'model.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.weight', 'model.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.bias', 'model.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.weight', 'model.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.bias', 'model.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.weight', 'model.vision_tower.vision_model.encoder.layers.14.layer_norm1.bias', 'model.vision_tower.vision_model.encoder.layers.14.layer_norm1.weight', 'model.vision_tower.vision_model.encoder.layers.14.layer_norm2.bias', 'model.vision_tower.vision_model.encoder.layers.14.layer_norm2.weight', 'model.vision_tower.vision_model.encoder.layers.14.mlp.fc1.bias', 'model.vision_tower.vision_model.encoder.layers.14.mlp.fc1.weight', 'model.vision_tower.vision_model.encoder.layers.14.mlp.fc2.bias', 'model.vision_tower.vision_model.encoder.layers.14.mlp.fc2.weight', 'model.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.bias', 'model.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.weight', 'model.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.bias', 'model.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.weight', 'model.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.bias', 'model.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.weight', 'model.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.bias', 'model.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.weight', 'model.vision_tower.vision_model.encoder.layers.15.layer_norm1.bias', 'model.vision_tower.vision_model.encoder.layers.15.layer_norm1.weight', 'model.vision_tower.vision_model.encoder.layers.15.layer_norm2.bias', 'model.vision_tower.vision_model.encoder.layers.15.layer_norm2.weight', 'model.vision_tower.vision_model.encoder.layers.15.mlp.fc1.bias', 'model.vision_tower.vision_model.encoder.layers.15.mlp.fc1.weight', 'model.vision_tower.vision_model.encoder.layers.15.mlp.fc2.bias', 'model.vision_tower.vision_model.encoder.layers.15.mlp.fc2.weight', 'model.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.bias', 'model.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.weight', 'model.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.bias', 'model.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.weight', 'model.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.bias', 'model.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.weight', 'model.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.bias', 'model.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.weight', 'model.vision_tower.vision_model.encoder.layers.16.layer_norm1.bias', 'model.vision_tower.vision_model.encoder.layers.16.layer_norm1.weight', 'model.vision_tower.vision_model.encoder.layers.16.layer_norm2.bias', 'model.vision_tower.vision_model.encoder.layers.16.layer_norm2.weight', 'model.vision_tower.vision_model.encoder.layers.16.mlp.fc1.bias', 'model.vision_tower.vision_model.encoder.layers.16.mlp.fc1.weight', 'model.vision_tower.vision_model.encoder.layers.16.mlp.fc2.bias', 'model.vision_tower.vision_model.encoder.layers.16.mlp.fc2.weight', 'model.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.bias', 'model.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.weight', 'model.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.bias', 'model.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.weight', 'model.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.bias', 'model.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.weight', 'model.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.bias', 'model.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.weight', 'model.vision_tower.vision_model.encoder.layers.17.layer_norm1.bias', 'model.vision_tower.vision_model.encoder.layers.17.layer_norm1.weight', 'model.vision_tower.vision_model.encoder.layers.17.layer_norm2.bias', 'model.vision_tower.vision_model.encoder.layers.17.layer_norm2.weight', 'model.vision_tower.vision_model.encoder.layers.17.mlp.fc1.bias', 'model.vision_tower.vision_model.encoder.layers.17.mlp.fc1.weight', 'model.vision_tower.vision_model.encoder.layers.17.mlp.fc2.bias', 'model.vision_tower.vision_model.encoder.layers.17.mlp.fc2.weight', 'model.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.bias', 'model.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.weight', 'model.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.bias', 'model.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.weight', 'model.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.bias', 'model.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.weight', 'model.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.bias', 'model.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.weight', 'model.vision_tower.vision_model.encoder.layers.18.layer_norm1.bias', 'model.vision_tower.vision_model.encoder.layers.18.layer_norm1.weight', 'model.vision_tower.vision_model.encoder.layers.18.layer_norm2.bias', 'model.vision_tower.vision_model.encoder.layers.18.layer_norm2.weight', 'model.vision_tower.vision_model.encoder.layers.18.mlp.fc1.bias', 'model.vision_tower.vision_model.encoder.layers.18.mlp.fc1.weight', 'model.vision_tower.vision_model.encoder.layers.18.mlp.fc2.bias', 'model.vision_tower.vision_model.encoder.layers.18.mlp.fc2.weight', 'model.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.bias', 'model.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.weight', 'model.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.bias', 'model.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.weight', 'model.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.bias', 'model.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.weight', 'model.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.bias', 'model.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.weight', 'model.vision_tower.vision_model.encoder.layers.19.layer_norm1.bias', 'model.vision_tower.vision_model.encoder.layers.19.layer_norm1.weight', 'model.vision_tower.vision_model.encoder.layers.19.layer_norm2.bias', 'model.vision_tower.vision_model.encoder.layers.19.layer_norm2.weight', 'model.vision_tower.vision_model.encoder.layers.19.mlp.fc1.bias', 'model.vision_tower.vision_model.encoder.layers.19.mlp.fc1.weight', 'model.vision_tower.vision_model.encoder.layers.19.mlp.fc2.bias', 'model.vision_tower.vision_model.encoder.layers.19.mlp.fc2.weight', 'model.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.bias', 'model.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.weight', 'model.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.bias', 'model.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.weight', 'model.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.bias', 'model.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.weight', 'model.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.bias', 'model.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.weight', 'model.vision_tower.vision_model.encoder.layers.2.layer_norm1.bias', 'model.vision_tower.vision_model.encoder.layers.2.layer_norm1.weight', 'model.vision_tower.vision_model.encoder.layers.2.layer_norm2.bias', 'model.vision_tower.vision_model.encoder.layers.2.layer_norm2.weight', 'model.vision_tower.vision_model.encoder.layers.2.mlp.fc1.bias', 'model.vision_tower.vision_model.encoder.layers.2.mlp.fc1.weight', 'model.vision_tower.vision_model.encoder.layers.2.mlp.fc2.bias', 'model.vision_tower.vision_model.encoder.layers.2.mlp.fc2.weight', 'model.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.bias', 'model.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.weight', 'model.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.bias', 'model.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.weight', 'model.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.bias', 'model.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.weight', 'model.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.bias', 'model.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.weight', 'model.vision_tower.vision_model.encoder.layers.20.layer_norm1.bias', 'model.vision_tower.vision_model.encoder.layers.20.layer_norm1.weight', 'model.vision_tower.vision_model.encoder.layers.20.layer_norm2.bias', 'model.vision_tower.vision_model.encoder.layers.20.layer_norm2.weight', 'model.vision_tower.vision_model.encoder.layers.20.mlp.fc1.bias', 'model.vision_tower.vision_model.encoder.layers.20.mlp.fc1.weight', 'model.vision_tower.vision_model.encoder.layers.20.mlp.fc2.bias', 'model.vision_tower.vision_model.encoder.layers.20.mlp.fc2.weight', 'model.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.bias', 'model.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.weight', 'model.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.bias', 'model.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.weight', 'model.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.bias', 'model.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.weight', 'model.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.bias', 'model.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.weight', 'model.vision_tower.vision_model.encoder.layers.21.layer_norm1.bias', 'model.vision_tower.vision_model.encoder.layers.21.layer_norm1.weight', 'model.vision_tower.vision_model.encoder.layers.21.layer_norm2.bias', 'model.vision_tower.vision_model.encoder.layers.21.layer_norm2.weight', 'model.vision_tower.vision_model.encoder.layers.21.mlp.fc1.bias', 'model.vision_tower.vision_model.encoder.layers.21.mlp.fc1.weight', 'model.vision_tower.vision_model.encoder.layers.21.mlp.fc2.bias', 'model.vision_tower.vision_model.encoder.layers.21.mlp.fc2.weight', 'model.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.bias', 'model.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.weight', 'model.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.bias', 'model.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.weight', 'model.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.bias', 'model.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.weight', 'model.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.bias', 'model.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.weight', 'model.vision_tower.vision_model.encoder.layers.22.layer_norm1.bias', 'model.vision_tower.vision_model.encoder.layers.22.layer_norm1.weight', 'model.vision_tower.vision_model.encoder.layers.22.layer_norm2.bias', 'model.vision_tower.vision_model.encoder.layers.22.layer_norm2.weight', 'model.vision_tower.vision_model.encoder.layers.22.mlp.fc1.bias', 'model.vision_tower.vision_model.encoder.layers.22.mlp.fc1.weight', 'model.vision_tower.vision_model.encoder.layers.22.mlp.fc2.bias', 'model.vision_tower.vision_model.encoder.layers.22.mlp.fc2.weight', 'model.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.bias', 'model.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.weight', 'model.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.bias', 'model.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.weight', 'model.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.bias', 'model.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.weight', 'model.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.bias', 'model.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.weight', 'model.vision_tower.vision_model.encoder.layers.23.layer_norm1.bias', 'model.vision_tower.vision_model.encoder.layers.23.layer_norm1.weight', 'model.vision_tower.vision_model.encoder.layers.23.layer_norm2.bias', 'model.vision_tower.vision_model.encoder.layers.23.layer_norm2.weight', 'model.vision_tower.vision_model.encoder.layers.23.mlp.fc1.bias', 'model.vision_tower.vision_model.encoder.layers.23.mlp.fc1.weight', 'model.vision_tower.vision_model.encoder.layers.23.mlp.fc2.bias', 'model.vision_tower.vision_model.encoder.layers.23.mlp.fc2.weight', 'model.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.bias', 'model.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.weight', 'model.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.bias', 'model.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.weight', 'model.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.bias', 'model.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.weight', 'model.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.bias', 'model.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.weight', 'model.vision_tower.vision_model.encoder.layers.3.layer_norm1.bias', 'model.vision_tower.vision_model.encoder.layers.3.layer_norm1.weight', 'model.vision_tower.vision_model.encoder.layers.3.layer_norm2.bias', 'model.vision_tower.vision_model.encoder.layers.3.layer_norm2.weight', 'model.vision_tower.vision_model.encoder.layers.3.mlp.fc1.bias', 'model.vision_tower.vision_model.encoder.layers.3.mlp.fc1.weight', 'model.vision_tower.vision_model.encoder.layers.3.mlp.fc2.bias', 'model.vision_tower.vision_model.encoder.layers.3.mlp.fc2.weight', 'model.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.bias', 'model.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.weight', 'model.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.bias', 'model.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.weight', 'model.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.bias', 'model.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.weight', 'model.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.bias', 'model.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.weight', 'model.vision_tower.vision_model.encoder.layers.4.layer_norm1.bias', 'model.vision_tower.vision_model.encoder.layers.4.layer_norm1.weight', 'model.vision_tower.vision_model.encoder.layers.4.layer_norm2.bias', 'model.vision_tower.vision_model.encoder.layers.4.layer_norm2.weight', 'model.vision_tower.vision_model.encoder.layers.4.mlp.fc1.bias', 'model.vision_tower.vision_model.encoder.layers.4.mlp.fc1.weight', 'model.vision_tower.vision_model.encoder.layers.4.mlp.fc2.bias', 'model.vision_tower.vision_model.encoder.layers.4.mlp.fc2.weight', 'model.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.bias', 'model.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.weight', 'model.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.bias', 'model.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.weight', 'model.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.bias', 'model.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.weight', 'model.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.bias', 'model.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.weight', 'model.vision_tower.vision_model.encoder.layers.5.layer_norm1.bias', 'model.vision_tower.vision_model.encoder.layers.5.layer_norm1.weight', 'model.vision_tower.vision_model.encoder.layers.5.layer_norm2.bias', 'model.vision_tower.vision_model.encoder.layers.5.layer_norm2.weight', 'model.vision_tower.vision_model.encoder.layers.5.mlp.fc1.bias', 'model.vision_tower.vision_model.encoder.layers.5.mlp.fc1.weight', 'model.vision_tower.vision_model.encoder.layers.5.mlp.fc2.bias', 'model.vision_tower.vision_model.encoder.layers.5.mlp.fc2.weight', 'model.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.bias', 'model.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.weight', 'model.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.bias', 'model.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.weight', 'model.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.bias', 'model.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.weight', 'model.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.bias', 'model.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.weight', 'model.vision_tower.vision_model.encoder.layers.6.layer_norm1.bias', 'model.vision_tower.vision_model.encoder.layers.6.layer_norm1.weight', 'model.vision_tower.vision_model.encoder.layers.6.layer_norm2.bias', 'model.vision_tower.vision_model.encoder.layers.6.layer_norm2.weight', 'model.vision_tower.vision_model.encoder.layers.6.mlp.fc1.bias', 'model.vision_tower.vision_model.encoder.layers.6.mlp.fc1.weight', 'model.vision_tower.vision_model.encoder.layers.6.mlp.fc2.bias', 'model.vision_tower.vision_model.encoder.layers.6.mlp.fc2.weight', 'model.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.bias', 'model.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.weight', 'model.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.bias', 'model.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.weight', 'model.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.bias', 'model.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.weight', 'model.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.bias', 'model.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.weight', 'model.vision_tower.vision_model.encoder.layers.7.layer_norm1.bias', 'model.vision_tower.vision_model.encoder.layers.7.layer_norm1.weight', 'model.vision_tower.vision_model.encoder.layers.7.layer_norm2.bias', 'model.vision_tower.vision_model.encoder.layers.7.layer_norm2.weight', 'model.vision_tower.vision_model.encoder.layers.7.mlp.fc1.bias', 'model.vision_tower.vision_model.encoder.layers.7.mlp.fc1.weight', 'model.vision_tower.vision_model.encoder.layers.7.mlp.fc2.bias', 'model.vision_tower.vision_model.encoder.layers.7.mlp.fc2.weight', 'model.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.bias', 'model.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.weight', 'model.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.bias', 'model.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.weight', 'model.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.bias', 'model.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.weight', 'model.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.bias', 'model.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.weight', 'model.vision_tower.vision_model.encoder.layers.8.layer_norm1.bias', 'model.vision_tower.vision_model.encoder.layers.8.layer_norm1.weight', 'model.vision_tower.vision_model.encoder.layers.8.layer_norm2.bias', 'model.vision_tower.vision_model.encoder.layers.8.layer_norm2.weight', 'model.vision_tower.vision_model.encoder.layers.8.mlp.fc1.bias', 'model.vision_tower.vision_model.encoder.layers.8.mlp.fc1.weight', 'model.vision_tower.vision_model.encoder.layers.8.mlp.fc2.bias', 'model.vision_tower.vision_model.encoder.layers.8.mlp.fc2.weight', 'model.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.bias', 'model.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.weight', 'model.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.bias', 'model.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.weight', 'model.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.bias', 'model.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.weight', 'model.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.bias', 'model.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.weight', 'model.vision_tower.vision_model.encoder.layers.9.layer_norm1.bias', 'model.vision_tower.vision_model.encoder.layers.9.layer_norm1.weight', 'model.vision_tower.vision_model.encoder.layers.9.layer_norm2.bias', 'model.vision_tower.vision_model.encoder.layers.9.layer_norm2.weight', 'model.vision_tower.vision_model.encoder.layers.9.mlp.fc1.bias', 'model.vision_tower.vision_model.encoder.layers.9.mlp.fc1.weight', 'model.vision_tower.vision_model.encoder.layers.9.mlp.fc2.bias', 'model.vision_tower.vision_model.encoder.layers.9.mlp.fc2.weight', 'model.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.bias', 'model.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.weight', 'model.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.bias', 'model.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.weight', 'model.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.bias', 'model.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.weight', 'model.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.bias', 'model.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.weight', 'model.vision_tower.vision_model.post_layernorm.bias', 'model.vision_tower.vision_model.post_layernorm.weight', 'model.vision_tower.vision_model.pre_layrnorm.bias', 'model.vision_tower.vision_model.pre_layrnorm.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
  0%|          | 0/2997 [00:00<?, ?it/s]  0%|          | 8/2997 [00:00<00:38, 77.68it/s]  1%|          | 20/2997 [00:00<00:29, 101.62it/s]  1%|          | 36/2997 [00:00<00:23, 125.43it/s]  2%|▏         | 51/2997 [00:00<00:21, 134.44it/s]  2%|▏         | 66/2997 [00:00<00:20, 139.58it/s]  3%|▎         | 80/2997 [00:00<00:21, 138.61it/s]  3%|▎         | 97/2997 [00:00<00:19, 146.59it/s]  4%|▍         | 113/2997 [00:00<00:19, 148.35it/s]  4%|▍         | 130/2997 [00:00<00:18, 153.05it/s]  5%|▍         | 146/2997 [00:01<00:18, 151.46it/s]  5%|▌         | 163/2997 [00:01<00:18, 154.63it/s]  6%|▌         | 180/2997 [00:01<00:17, 158.75it/s]  7%|▋         | 198/2997 [00:01<00:17, 162.88it/s]  7%|▋         | 215/2997 [00:01<00:17, 158.91it/s]  8%|▊         | 232/2997 [00:01<00:17, 159.92it/s]  8%|▊         | 249/2997 [00:01<00:17, 161.35it/s]  9%|▉         | 266/2997 [00:01<00:17, 159.30it/s]  9%|▉         | 282/2997 [00:01<00:17, 159.48it/s] 10%|▉         | 299/2997 [00:01<00:16, 160.77it/s] 11%|█         | 316/2997 [00:02<00:17, 155.30it/s] 11%|█         | 334/2997 [00:02<00:16, 159.84it/s] 12%|█▏        | 351/2997 [00:02<00:16, 160.21it/s] 12%|█▏        | 368/2997 [00:02<00:16, 162.60it/s] 13%|█▎        | 386/2997 [00:02<00:15, 165.73it/s] 13%|█▎        | 404/2997 [00:02<00:15, 167.47it/s] 14%|█▍        | 422/2997 [00:02<00:15, 171.10it/s] 15%|█▍        | 440/2997 [00:02<00:14, 172.09it/s] 15%|█▌        | 458/2997 [00:02<00:15, 163.19it/s] 16%|█▌        | 475/2997 [00:03<00:15, 163.64it/s] 16%|█▋        | 492/2997 [00:03<00:15, 163.46it/s] 17%|█▋        | 509/2997 [00:03<00:15, 164.70it/s] 18%|█▊        | 526/2997 [00:03<00:15, 162.83it/s] 18%|█▊        | 543/2997 [00:03<00:15, 159.86it/s] 19%|█▊        | 561/2997 [00:03<00:14, 164.31it/s] 19%|█▉        | 578/2997 [00:03<00:14, 163.70it/s] 20%|█▉        | 596/2997 [00:03<00:14, 166.14it/s] 20%|██        | 613/2997 [00:03<00:14, 166.40it/s] 21%|██        | 630/2997 [00:03<00:14, 164.64it/s] 22%|██▏       | 648/2997 [00:04<00:14, 166.80it/s] 22%|██▏       | 665/2997 [00:04<00:14, 164.37it/s] 23%|██▎       | 682/2997 [00:04<00:14, 161.97it/s] 23%|██▎       | 699/2997 [00:04<00:13, 164.24it/s] 24%|██▍       | 717/2997 [00:04<00:13, 166.72it/s] 24%|██▍       | 734/2997 [00:04<00:13, 161.94it/s] 25%|██▌       | 751/2997 [00:04<00:14, 159.37it/s] 26%|██▌       | 767/2997 [00:04<00:14, 156.71it/s] 26%|██▌       | 784/2997 [00:04<00:13, 159.10it/s] 27%|██▋       | 800/2997 [00:05<00:13, 158.87it/s] 27%|██▋       | 818/2997 [00:05<00:13, 163.61it/s] 28%|██▊       | 835/2997 [00:05<00:13, 165.00it/s] 28%|██▊       | 852/2997 [00:05<00:12, 166.38it/s] 29%|██▉       | 869/2997 [00:05<00:12, 165.57it/s] 30%|██▉       | 886/2997 [00:05<00:12, 164.16it/s] 30%|███       | 904/2997 [00:05<00:12, 166.04it/s] 31%|███       | 921/2997 [00:05<00:12, 164.99it/s] 31%|███▏      | 938/2997 [00:05<00:12, 165.40it/s] 32%|███▏      | 955/2997 [00:05<00:12, 164.90it/s] 32%|███▏      | 972/2997 [00:06<00:12, 166.21it/s] 33%|███▎      | 989/2997 [00:06<00:12, 161.79it/s] 34%|███▎      | 1006/2997 [00:06<00:12, 157.75it/s] 34%|███▍      | 1022/2997 [00:06<00:12, 155.36it/s] 35%|███▍      | 1039/2997 [00:06<00:12, 157.31it/s] 35%|███▌      | 1056/2997 [00:06<00:12, 158.87it/s] 36%|███▌      | 1074/2997 [00:06<00:11, 163.78it/s] 36%|███▋      | 1091/2997 [00:06<00:11, 163.69it/s] 37%|███▋      | 1108/2997 [00:06<00:11, 165.48it/s] 38%|███▊      | 1126/2997 [00:07<00:11, 167.28it/s] 38%|███▊      | 1144/2997 [00:07<00:11, 168.18it/s] 39%|███▊      | 1161/2997 [00:07<00:11, 164.47it/s] 39%|███▉      | 1178/2997 [00:07<00:11, 159.53it/s] 40%|███▉      | 1195/2997 [00:07<00:11, 161.66it/s] 40%|████      | 1213/2997 [00:07<00:10, 165.85it/s] 41%|████      | 1230/2997 [00:07<00:10, 163.65it/s] 42%|████▏     | 1248/2997 [00:07<00:10, 165.63it/s] 42%|████▏     | 1265/2997 [00:07<00:10, 164.54it/s] 43%|████▎     | 1282/2997 [00:08<00:10, 157.58it/s] 43%|████▎     | 1299/2997 [00:08<00:10, 159.26it/s] 44%|████▍     | 1315/2997 [00:08<00:10, 155.18it/s] 44%|████▍     | 1333/2997 [00:08<00:10, 159.70it/s] 45%|████▌     | 1350/2997 [00:08<00:10, 162.45it/s] 46%|████▌     | 1367/2997 [00:08<00:09, 164.21it/s] 46%|████▌     | 1384/2997 [00:08<00:09, 165.06it/s] 47%|████▋     | 1402/2997 [00:08<00:09, 168.47it/s] 47%|████▋     | 1419/2997 [00:08<00:09, 168.75it/s] 48%|████▊     | 1436/2997 [00:08<00:09, 167.46it/s] 48%|████▊     | 1453/2997 [00:09<00:09, 166.62it/s] 49%|████▉     | 1471/2997 [00:09<00:08, 169.57it/s] 50%|████▉     | 1488/2997 [00:09<00:09, 166.41it/s] 50%|█████     | 1505/2997 [00:09<00:09, 163.88it/s] 51%|█████     | 1522/2997 [00:09<00:09, 161.23it/s] 51%|█████▏    | 1539/2997 [00:09<00:09, 158.24it/s] 52%|█████▏    | 1556/2997 [00:09<00:09, 159.45it/s] 52%|█████▏    | 1573/2997 [00:09<00:08, 158.62it/s] 53%|█████▎    | 1590/2997 [00:09<00:08, 160.74it/s] 54%|█████▎    | 1608/2997 [00:09<00:08, 166.01it/s] 54%|█████▍    | 1625/2997 [00:10<00:08, 165.53it/s] 55%|█████▍    | 1643/2997 [00:10<00:08, 167.90it/s] 55%|█████▌    | 1660/2997 [00:10<00:08, 163.88it/s] 56%|█████▌    | 1677/2997 [00:10<00:08, 159.47it/s] 56%|█████▋    | 1693/2997 [00:10<00:08, 159.51it/s] 57%|█████▋    | 1710/2997 [00:10<00:08, 160.53it/s] 58%|█████▊    | 1727/2997 [00:10<00:07, 158.90it/s] 58%|█████▊    | 1743/2997 [00:10<00:08, 150.37it/s] 59%|█████▊    | 1759/2997 [00:10<00:08, 149.48it/s] 59%|█████▉    | 1776/2997 [00:11<00:07, 153.60it/s] 60%|█████▉    | 1792/2997 [00:11<00:07, 153.13it/s] 60%|██████    | 1810/2997 [00:11<00:07, 159.49it/s] 61%|██████    | 1827/2997 [00:11<00:07, 161.68it/s] 62%|██████▏   | 1844/2997 [00:11<00:07, 161.39it/s] 62%|██████▏   | 1861/2997 [00:11<00:06, 163.10it/s] 63%|██████▎   | 1878/2997 [00:11<00:06, 165.00it/s] 63%|██████▎   | 1895/2997 [00:11<00:06, 165.54it/s] 64%|██████▍   | 1912/2997 [00:11<00:06, 163.04it/s] 64%|██████▍   | 1929/2997 [00:11<00:06, 162.95it/s] 65%|██████▍   | 1947/2997 [00:12<00:06, 165.79it/s] 66%|██████▌   | 1964/2997 [00:12<00:06, 166.83it/s] 66%|██████▌   | 1981/2997 [00:12<00:06, 167.70it/s] 67%|██████▋   | 2000/2997 [00:12<00:05, 173.46it/s] 67%|██████▋   | 2018/2997 [00:12<00:05, 172.57it/s] 68%|██████▊   | 2036/2997 [00:12<00:05, 172.91it/s] 69%|██████▊   | 2054/2997 [00:12<00:05, 173.35it/s] 69%|██████▉   | 2072/2997 [00:12<00:05, 172.70it/s] 70%|██████▉   | 2090/2997 [00:12<00:05, 170.41it/s] 70%|███████   | 2108/2997 [00:13<00:05, 168.90it/s] 71%|███████   | 2126/2997 [00:13<00:05, 170.81it/s] 72%|███████▏  | 2144/2997 [00:13<00:05, 168.03it/s] 72%|███████▏  | 2162/2997 [00:13<00:04, 169.21it/s] 73%|███████▎  | 2180/2997 [00:13<00:04, 170.09it/s] 73%|███████▎  | 2198/2997 [00:13<00:04, 172.51it/s] 74%|███████▍  | 2216/2997 [00:13<00:04, 172.72it/s] 75%|███████▍  | 2234/2997 [00:13<00:04, 171.76it/s] 75%|███████▌  | 2252/2997 [00:13<00:04, 167.28it/s] 76%|███████▌  | 2269/2997 [00:13<00:04, 167.85it/s] 76%|███████▋  | 2286/2997 [00:14<00:04, 165.43it/s] 77%|███████▋  | 2303/2997 [00:14<00:04, 166.23it/s] 77%|███████▋  | 2320/2997 [00:14<00:04, 167.20it/s] 78%|███████▊  | 2337/2997 [00:14<00:04, 164.29it/s] 79%|███████▊  | 2355/2997 [00:14<00:03, 167.51it/s] 79%|███████▉  | 2372/2997 [00:14<00:03, 167.84it/s] 80%|███████▉  | 2390/2997 [00:14<00:03, 169.51it/s] 80%|████████  | 2407/2997 [00:14<00:03, 169.60it/s] 81%|████████  | 2425/2997 [00:14<00:03, 170.93it/s] 82%|████████▏ | 2443/2997 [00:15<00:03, 162.15it/s] 82%|████████▏ | 2461/2997 [00:15<00:03, 163.59it/s] 83%|████████▎ | 2478/2997 [00:15<00:03, 165.12it/s] 83%|████████▎ | 2495/2997 [00:15<00:03, 152.98it/s] 84%|████████▍ | 2511/2997 [00:15<00:03, 147.53it/s] 84%|████████▍ | 2526/2997 [00:15<00:03, 145.29it/s] 85%|████████▍ | 2543/2997 [00:15<00:03, 150.02it/s] 85%|████████▌ | 2560/2997 [00:15<00:02, 154.23it/s] 86%|████████▌ | 2576/2997 [00:15<00:02, 154.03it/s] 87%|████████▋ | 2593/2997 [00:16<00:02, 155.80it/s] 87%|████████▋ | 2609/2997 [00:16<00:02, 154.34it/s] 88%|████████▊ | 2625/2997 [00:16<00:02, 151.40it/s] 88%|████████▊ | 2641/2997 [00:16<00:02, 152.82it/s] 89%|████████▊ | 2657/2997 [00:16<00:02, 153.30it/s] 89%|████████▉ | 2674/2997 [00:16<00:02, 157.87it/s] 90%|████████▉ | 2692/2997 [00:16<00:01, 161.66it/s] 90%|█████████ | 2709/2997 [00:16<00:01, 160.46it/s] 91%|█████████ | 2726/2997 [00:16<00:01, 158.56it/s] 92%|█████████▏| 2744/2997 [00:16<00:01, 162.22it/s] 92%|█████████▏| 2761/2997 [00:17<00:01, 161.72it/s] 93%|█████████▎| 2778/2997 [00:17<00:01, 153.22it/s] 93%|█████████▎| 2795/2997 [00:17<00:01, 157.46it/s] 94%|█████████▍| 2813/2997 [00:17<00:01, 161.45it/s] 94%|█████████▍| 2830/2997 [00:17<00:01, 162.63it/s] 95%|█████████▍| 2847/2997 [00:17<00:00, 157.65it/s] 96%|█████████▌| 2864/2997 [00:17<00:00, 158.54it/s] 96%|█████████▌| 2882/2997 [00:17<00:00, 163.19it/s] 97%|█████████▋| 2900/2997 [00:17<00:00, 166.63it/s] 97%|█████████▋| 2918/2997 [00:18<00:00, 168.32it/s] 98%|█████████▊| 2936/2997 [00:18<00:00, 171.25it/s] 99%|█████████▊| 2954/2997 [00:18<00:00, 170.06it/s] 99%|█████████▉| 2972/2997 [00:18<00:00, 169.58it/s]100%|█████████▉| 2990/2997 [00:18<00:00, 172.09it/s]100%|██████████| 2997/2997 [00:18<00:00, 159.88it/s]
